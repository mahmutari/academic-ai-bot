# Academic Second Brain: Local RAG-Based AI Assistant


![Academic Second Brain Demo](assets/demo-screenshot.png)

Academic Second Brain, gizlilik odaklÄ± ve tamamen yerel (local) Ã§alÄ±ÅŸan, akademik dÃ¶kÃ¼manlarÄ± analiz edebilen hibrit bir yapay zeka asistanÄ±dÄ±r. KullanÄ±cÄ±lar PDF dÃ¶kÃ¼manlarÄ±nÄ± yÃ¼kleyerek spesifik teknik sorular sorabilir veya asistanÄ±n genel akademik bilgisinden (dil bilgisi, matematik, felsefe vb.) yararlanabilirler.

---

## ğŸš€ Ã–ne Ã‡Ä±kan Ã–zellikler

- **Yerel LLM Entegrasyonu**: Verileriniz internete Ã§Ä±kmaz; Ollama aracÄ±lÄ±ÄŸÄ±yla Llama 3.2 3B modeli tamamen yerel makinede Ã§alÄ±ÅŸÄ±r.

- **Hibrit Bilgi Sistemi**: Soru dÃ¶kÃ¼manla ilgiliyse RAG (Retrieval-Augmented Generation) mekanizmasÄ±, genel bir konuysa LLM'in Ã¶nceden eÄŸitilmiÅŸ genel bilgisi devreye girer.

- **AkÄ±llÄ± Kaynak GÃ¶sterme**: Cevap dÃ¶kÃ¼mandan alÄ±ndÄ±ÄŸÄ±nda, bilginin hangi sayfadan geldiÄŸi otomatik olarak ğŸ“ *(Kaynak: Sayfa X)* ÅŸeklinde belirtilir.

- **In-Memory Vector Store**: Windows iÅŸletim sistemindeki dosya kilitleme hatalarÄ±nÄ± (WinError 32) Ã¶nlemek ve maksimum hÄ±za ulaÅŸmak iÃ§in veritabanÄ± (ChromaDB) RAM Ã¼zerinde Ã§alÄ±ÅŸÄ±r.

- **GeliÅŸmiÅŸ Metin Ä°ÅŸleme**: DÃ¶kÃ¼manlar, anlam bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ korumak adÄ±na akÄ±llÄ± parÃ§alama (Recursive Character Splitting) yÃ¶nteminden geÃ§er.

---

## ğŸ› ï¸ Teknik Mimari

Proje, modern bir AI boru hattÄ± (pipeline) Ã¼zerine inÅŸa edilmiÅŸtir:

1. **Ingestion**: PDF dÃ¶kÃ¼manlarÄ± `PyPDFLoader` ile taranÄ±r.
2. **Processing**: Metinler HuggingFace embedding modelleri (`all-MiniLM-L6-v2`) kullanÄ±larak vektÃ¶rleÅŸtirilir.
3. **Storage**: VektÃ¶rler RAM Ã¼zerindeki ChromaDB iÃ§erisinde geÃ§ici olarak saklanÄ±r.
4. **Retrieval**: KullanÄ±cÄ± sorusuna en yakÄ±n anlam parÃ§alarÄ± (chunks) anlÄ±k olarak geri Ã§aÄŸrÄ±lÄ±r.
5. **Generation**: Prompt Engineering teknikleriyle LLM'e baÄŸlam (context) sunulur ve yanÄ±t Ã¼retilir.

---

## ğŸ“¦ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### Gereksinimler

- Python 3.10+
- Ollama (Llama 3.2 modeli yÃ¼klÃ¼ olmalÄ±dÄ±r)

### AdÄ±mlar

1. **Depoyu klonlayÄ±n:**
   ```bash
   git clone https://github.com/mahmutari/academic-ai-bot.git
   cd academic-ai-bot
   ```

2. **Gerekli kÃ¼tÃ¼phaneleri kurun:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Ollama'da Llama 3.2 modelini yÃ¼kleyin:**
   ```bash
   ollama pull llama3.2
   ```

4. **UygulamayÄ± baÅŸlatÄ±n:**
   ```bash
   streamlit run app.py
   ```

5. **TarayÄ±cÄ±nÄ±zda aÃ§Ä±lan arayÃ¼zÃ¼ kullanÄ±n** (genellikle `http://localhost:8501`)

---

## ğŸ’¡ KullanÄ±m

1. UygulamayÄ± baÅŸlattÄ±ktan sonra sol taraftaki sidebar'dan PDF dosyanÄ±zÄ± yÃ¼kleyin
2. "DÃ¶kÃ¼manÄ± Ä°ÅŸle" butonuna tÄ±klayÄ±n
3. Soru kutusuna akademik sorunuzu yazÄ±n
4. Asistan, eÄŸer cevap dÃ¶kÃ¼manda varsa kaynak sayfa numarasÄ±yla birlikte yanÄ±t verecektir

---

## ğŸ“ˆ Gelecek Ã‡alÄ±ÅŸmalar (Future Work)

Projenin geliÅŸim vizyonu ÅŸu hedefleri iÃ§ermektedir:

- [ ] **Global Summarization**: DÃ¶kÃ¼manÄ±n tamamÄ±nÄ± tek seferde Ã¶zetleyebilen bÃ¼yÃ¼k baÄŸlamlÄ± modellerin entegrasyonu
- [ ] **Multi-Document Support**: AynÄ± anda birden fazla PDF Ã¼zerinde Ã§apraz sorgulama yeteneÄŸi
- [ ] **Dark Mode & UI**: Daha geliÅŸmiÅŸ bir kullanÄ±cÄ± deneyimi iÃ§in karanlÄ±k mod ve PDF Ã¶nizleme paneli
- [ ] **Advanced Search**: Semantic search ve keyword search kombinasyonu
- [ ] **Export Options**: Soru-cevap geÃ§miÅŸini PDF veya Markdown olarak dÄ±ÅŸa aktarma

---

## ğŸ¤ KatkÄ±da Bulunma

1. Bu depoyu fork edin
2. Yeni bir branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'feat: Add amazing feature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. Bir Pull Request aÃ§Ä±n

---



## ğŸ™ TeÅŸekkÃ¼rler

Bu proje aÅŸaÄŸÄ±daki aÃ§Ä±k kaynak teknolojileri kullanmaktadÄ±r:

- [LangChain](https://github.com/langchain-ai/langchain)
- [Ollama](https://ollama.ai/)
- [ChromaDB](https://www.trychroma.com/)
- [Streamlit](https://streamlit.io/)
- [HuggingFace](https://huggingface.co/)

---

